gen_test_data: false
download: true
infer: true
model: "mistral_7b_q8"

# Infer parameters
n_threads: 8
n_gpu_layers: 0
verbose: false
req_cols:
  - "id"
  - "pub_date"
  - "ticker"
  - "title"
  - "content"
  - "rating"
  - "reasons"

# Directory path
path:
  model_dir: "./models"
  data_dir: "./data"
  divergent: "${path.data_dir}/divergent.csv"
  test: "${path.data_dir}/test.csv"
  script: "./src/local_llm.py"

# Graph settings
fig:
  theme:
      style: "whitegrid"
      palette: "pastel"
      font_scale: 1.5
  heatmap:
      annot: true # Display values in confusion matrix
      fmt: "d" # Display values as integer
      cmap: "Blues" # Seaborn color map
      cbar: true # Display color bar


########################
# Gemma
########################

gemma:
  family: "gemma"
  class_name: "GemmaLLM"
  data_dir: "${path.data_dir}/${gemma.family}"
  model_dir: "${path.model_dir}/${gemma.family}"

gemma_4b:
  repo_id: "google/gemma-3-4b-it-qat-q4_0-gguf"
  filename: "gemma-3-4b-it-q4_0.gguf"
  ratings_path: "${gemma.data_dir}/ratings_gemma_4b.csv"
  metrics_path: "${gemma.data_dir}/metrics_gemma_4b.csv"

  download:
    repo_id: "${gemma_4b.repo_id}"
    filename: "${gemma_4b.filename}"
    model_dir: "${gemma.model_dir}"
    token: "${oc.env:HF_KEY}"

  infer:
    class_name: "${gemma.class_name}"
    script_path: "${path.script}"
    model_path: "${gemma.model_dir}/${gemma_4b.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"

gemma_12b:
  repo_id: "google/gemma-3-12b-it-qat-q4_0-gguf"
  filename: "gemma-3-12b-it-q4_0.gguf" # 8.07 GB
  ratings_path: "${gemma.data_dir}/ratings_gemma_12b.csv"
  metrics_path: "${gemma.data_dir}/metrics_gemma_12b.csv"

  download:
    repo_id: "${gemma_12b.repo_id}"
    filename: "${gemma_12b.filename}"
    model_dir: "${gemma.model_dir}"
    token: "${oc.env:HF_KEY}"

  infer:
    class_name: "${gemma.class_name}"
    script_path: "${path.script}"
    model_path: "${gemma.model_dir}/${gemma_12b.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"

gemma_27b:
  repo_id: "google/gemma-3-27b-it-qat-q4_0-gguf"
  filename: "gemma-3-27b-it-q4_0.gguf" # 17.2GB -> 15.7GB RAM
  ratings_path: "${gemma.data_dir}/ratings_gemma_27b.csv"
  metrics_path: "${gemma.data_dir}/metrics_gemma_27b.csv"

  download:
    repo_id: "${gemma_27b.repo_id}"
    filename: "${gemma_27b.filename}"
    model_dir: "${gemma.model_dir}"
    token: "${oc.env:HF_KEY}"

  infer:
    class_name: "${gemma.class_name}"
    script_path: "${path.script}"
    model_path: "${gemma.model_dir}/${gemma_27b.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"

########################
# Mistral
########################

mistral:
  family: "mistral"
  class_name: "MistralLLM"
  data_dir: "${path.data_dir}/${mistral.family}"
  model_dir: "${path.model_dir}/${mistral.family}"

mistral_7b_q8:
  repo_id: "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
  filename: "mistral-7b-instruct-v0.1.Q8_0.gguf"
  ratings_path: "${mistral.data_dir}/ratings_mistral_7b_q8.csv"
  metrics_path: "${mistral.data_dir}/metrics_mistral_7b_q8.csv"

  download:
    repo_id: "${mistral_7b_q8.repo_id}"
    filename: "${mistral_7b_q8.filename}"
    model_dir: "${mistral.model_dir}"
    # token: "${oc.env:HF_KEY}"
    token: null

  infer:
    class_name: "${mistral.class_name}"
    script_path: "${path.script}"
    model_path: "${mistral.model_dir}/${mistral_7b_q8.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    chat_format: "mistral-instruct"
