gen_test_data: false
download: true
infer: true
model: "llama_31_8b"
start_id: 0

# Infer parameters
n_threads: 8
n_gpu_layers: 0
verbose: false
req_cols:
  - "id"
  - "pub_date"
  - "ticker"
  - "title"
  - "content"
  - "rating"
  - "reasons"

# Directory path
path:
  model_dir: "./models"
  data_dir: "./data"
  divergent: "${path.data_dir}/divergent.csv"
  test: "${path.data_dir}/test.csv"
  script: "./src/local_llm.py"

# Graph settings
fig:
  theme:
      style: "whitegrid"
      palette: "pastel"
      font_scale: 1.5
  heatmap:
      annot: true # Display values in confusion matrix
      fmt: "d" # Display values as integer
      cmap: "Blues" # Seaborn color map
      cbar: true # Display color bar


########################
# Gemma
########################

gemma:
  family: "gemma"
  class_name: "LlamaLLM"
  data_dir: "${path.data_dir}/${gemma.family}"
  model_dir: "${path.model_dir}/${gemma.family}"

gemma_4b:
  repo_id: "google/gemma-3-4b-it-qat-q4_0-gguf"
  filename: "gemma-3-4b-it-q4_0.gguf"
  ratings_path: "${gemma.data_dir}/ratings_gemma_4b.csv"
  metrics_path: "${gemma.data_dir}/metrics_gemma_4b.csv"

  download:
    repo_id: "${gemma_4b.repo_id}"
    filename: "${gemma_4b.filename}"
    model_dir: "${gemma.model_dir}"
    token: "${oc.env:HF_KEY}"

  infer:
    class_name: "${gemma.class_name}"
    script_path: "${path.script}"
    model_path: "${gemma.model_dir}/${gemma_4b.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"

gemma_12b:
  repo_id: "google/gemma-3-12b-it-qat-q4_0-gguf"
  filename: "gemma-3-12b-it-q4_0.gguf" # 8.07 GB
  ratings_path: "${gemma.data_dir}/ratings_gemma_12b.csv"
  metrics_path: "${gemma.data_dir}/metrics_gemma_12b.csv"

  download:
    repo_id: "${gemma_12b.repo_id}"
    filename: "${gemma_12b.filename}"
    model_dir: "${gemma.model_dir}"
    token: "${oc.env:HF_KEY}"

  infer:
    class_name: "${gemma.class_name}"
    script_path: "${path.script}"
    model_path: "${gemma.model_dir}/${gemma_12b.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"

gemma_27b:
  repo_id: "google/gemma-3-27b-it-qat-q4_0-gguf"
  filename: "gemma-3-27b-it-q4_0.gguf" # 17.2GB -> 15.7GB RAM
  ratings_path: "${gemma.data_dir}/ratings_gemma_27b.csv"
  metrics_path: "${gemma.data_dir}/metrics_gemma_27b.csv"

  download:
    repo_id: "${gemma_27b.repo_id}"
    filename: "${gemma_27b.filename}"
    model_dir: "${gemma.model_dir}"
    token: "${oc.env:HF_KEY}"

  infer:
    class_name: "${gemma.class_name}"
    script_path: "${path.script}"
    model_path: "${gemma.model_dir}/${gemma_27b.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"

########################
# Mistral
########################

mistral:
  family: "mistral"
  class_name: "MistralLLM"
  data_dir: "${path.data_dir}/${mistral.family}"
  model_dir: "${path.model_dir}/${mistral.family}"

mistral_7b_q8:
  repo_id: "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
  filename: "mistral-7b-instruct-v0.1.Q8_0.gguf"
  ratings_path: "${mistral.data_dir}/ratings_mistral_7b_q8.csv"
  metrics_path: "${mistral.data_dir}/metrics_mistral_7b_q8.csv"

  download:
    repo_id: "${mistral_7b_q8.repo_id}"
    filename: "${mistral_7b_q8.filename}"
    model_dir: "${mistral.model_dir}"
    token: null

  infer:
    class_name: "${mistral.class_name}"
    script_path: "${path.script}"
    model_path: "${mistral.model_dir}/${mistral_7b_q8.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    chat_format: "mistral-instruct"

mistral_7b_q6:
  repo_id: "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
  filename: "mistral-7b-instruct-v0.1.Q6_K.gguf"
  ratings_path: "${mistral.data_dir}/ratings_mistral_7b_q6.csv"
  metrics_path: "${mistral.data_dir}/metrics_mistral_7b_q6.csv"

  download:
    repo_id: "${mistral_7b_q6.repo_id}"
    filename: "${mistral_7b_q6.filename}"
    model_dir: "${mistral.model_dir}"
    token: null

  infer:
    class_name: "${mistral.class_name}"
    script_path: "${path.script}"
    model_path: "${mistral.model_dir}/${mistral_7b_q6.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    chat_format: "mistral-instruct"

mistral_7b_q5_km:
  repo_id: "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
  filename: "mistral-7b-instruct-v0.1.Q5_K_M.gguf"
  ratings_path: "${mistral.data_dir}/ratings_mistral_7b_q5_km.csv"
  metrics_path: "${mistral.data_dir}/metrics_mistral_7b_q5_km.csv"

  download:
    repo_id: "${mistral_7b_q5_km.repo_id}"
    filename: "${mistral_7b_q5_km.filename}"
    model_dir: "${mistral.model_dir}"
    token: null

  infer:
    class_name: "${mistral.class_name}"
    script_path: "${path.script}"
    model_path: "${mistral.model_dir}/${mistral_7b_q5_km.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    chat_format: "mistral-instruct"

mistral_7b_q5_ks:
  repo_id: "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
  filename: "mistral-7b-instruct-v0.1.Q5_K_S.gguf"
  ratings_path: "${mistral.data_dir}/ratings_mistral_7b_q5_ks.csv"
  metrics_path: "${mistral.data_dir}/metrics_mistral_7b_q5_ks.csv"

  download:
    repo_id: "${mistral_7b_q5_ks.repo_id}"
    filename: "${mistral_7b_q5_ks.filename}"
    model_dir: "${mistral.model_dir}"
    token: null

  infer:
    class_name: "${mistral.class_name}"
    script_path: "${path.script}"
    model_path: "${mistral.model_dir}/${mistral_7b_q5_ks.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    chat_format: "mistral-instruct"
    stop:
      - "</s>"
      - "[INST]"
      - "[/INST]"

mistral_7b_q4_km:
  repo_id: "TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
  filename: "mistral-7b-instruct-v0.1.Q4_K_M.gguf"
  ratings_path: "${mistral.data_dir}/ratings_mistral_7b_q4_km.csv"
  metrics_path: "${mistral.data_dir}/metrics_mistral_7b_q4_km.csv"

  download:
    repo_id: "${mistral_7b_q4_km.repo_id}"
    filename: "${mistral_7b_q4_km.filename}"
    model_dir: "${mistral.model_dir}"
    token: null

  infer:
    class_name: "${mistral.class_name}"
    script_path: "${path.script}"
    model_path: "${mistral.model_dir}/${mistral_7b_q4_km.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    chat_format: "mistral-instruct"


########################
# Llama 3
########################

llama:
  family: "llama"
  class_name: "LlamaLLM"
  data_dir: "${path.data_dir}/${llama.family}"
  model_dir: "${path.model_dir}/${llama.family}"


llama_31_8b:
  repo_id: "mradermacher/Llama-3.1-8B-SpecialTitanFusion-GGUF"
  filename: "Llama-3.1-8B-SpecialTitanFusion.Q8_0.gguf"
  ratings_path: "${llama.data_dir}/ratings_llama_31_8b.csv"
  metrics_path: "${llama.data_dir}/metrics_llama_31_8b.csv"

  download:
    repo_id: "${llama_31_8b.repo_id}"
    filename: "${llama_31_8b.filename}"
    model_dir: "${llama.model_dir}"
    token: null

  infer:
    class_name: "${llama.class_name}"
    script_path: "${path.script}"
    model_path: "${llama.model_dir}/${llama_31_8b.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"

llama_32_3b:
  repo_id: "bartowski/Llama-3.2-3B-Instruct-GGUF"
  filename: "Llama-3.2-3B-Instruct-Q8_0.gguf"
  ratings_path: "${llama.data_dir}/ratings_llama_32_3b.csv"
  metrics_path: "${llama.data_dir}/metrics_llama_32_3b.csv"

  download:
    repo_id: "${llama_32_3b.repo_id}"
    filename: "${llama_32_3b.filename}"
    model_dir: "${llama.model_dir}"
    token: null

  infer:
    class_name: "${llama.class_name}"
    script_path: "${path.script}"
    model_path: "${llama.model_dir}/${llama_32_3b.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"

########################
# Qwen
########################

qwen:
  family: "qwen"
  class_name: "QwenLLM"
  data_dir: "${path.data_dir}/${qwen.family}"
  model_dir: "${path.model_dir}/${qwen.family}"

qwen_3_8b_q4_km:
  repo_id: "mradermacher/Qwen3-8B-GGUF"
  filename: "Qwen3-8B.Q4_K_M.gguf"
  ratings_path: "${qwen.data_dir}/ratings_qwen_3_8b_q4_km.csv"
  metrics_path: "${qwen.data_dir}/metrics_qwen_3_8b_q4_km.csv"

  download:
    repo_id: "${qwen_3_8b_q4_km.repo_id}"
    filename: "${qwen_3_8b_q4_km.filename}"
    model_dir: "${qwen.model_dir}"
    token: null

  infer:
    class_name: "${qwen.class_name}"
    script_path: "${path.script}"
    model_path: "${qwen.model_dir}/${qwen_3_8b_q4_km.filename}"
    n_ctx: 2048 # max 40960
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    chat_format: "chatml"
    rope_freq_base: 1000000.0
    temperature: 0.7
    top_p: 0.8
    top_k: 20
    min_p: 0
    max_tokens: 128

########################
# DeepSeek
########################

deepseek:
  family: "deepseek"
  class_name: "DeepSeekLLM"
  data_dir: "${path.data_dir}/${deepseek.family}"
  model_dir: "${path.model_dir}/${deepseek.family}"

deepseek_r1_llama_8b:
  repo_id: "unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF"
  filename: "DeepSeek-R1-Distill-Llama-8B-Q6_K.gguf"
  ratings_path: "${deepseek.data_dir}/ratings_deepseek_r1_llama_8b.csv"
  metrics_path: "${deepseek.data_dir}/metrics_deepseek_r1_llama_8b.csv"

  download:
    repo_id: "${deepseek_r1_llama_8b.repo_id}"
    filename: "${deepseek_r1_llama_8b.filename}"
    model_dir: "${deepseek.model_dir}"
    token: null

  infer:
    class_name: "${deepseek.class_name}"
    script_path: "${path.script}"
    model_path: "${deepseek.model_dir}/${deepseek_r1_llama_8b.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    stop:
      - "< | User | >"
    temperature: 0.6
    top_p: 0.95

deepseek_r1_qwen_14b_q8:
  repo_id: "bartowski/DeepSeek-R1-Distill-Qwen-14B-GGUF"
  filename: "DeepSeek-R1-Distill-Qwen-14B-Q8_0.gguf"
  ratings_path: "${deepseek.data_dir}/ratings_deepseek_r1_qwen_14b_q8.csv"
  metrics_path: "${deepseek.data_dir}/metrics_deepseek_r1_qwen_14b_q8.csv"

  download:
    repo_id: "${deepseek_r1_qwen_14b_q8.repo_id}"
    filename: "${deepseek_r1_qwen_14b_q8.filename}"
    model_dir: "${deepseek.model_dir}"
    token: null

  infer:
    class_name: "${deepseek.class_name}"
    script_path: "${path.script}"
    model_path: "${deepseek.model_dir}/${deepseek_r1_qwen_14b_q8.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    stop:
      - "< | User | >"
    temperature: 0.6
    top_p: 0.95

deepseek_r1_qwen_7b_q8:
  repo_id: "lmstudio-community/DeepSeek-R1-Distill-Qwen-7B-GGUF"
  filename: "DeepSeek-R1-Distill-Qwen-7B-Q8_0.gguf"
  ratings_path: "${deepseek.data_dir}/ratings_deepseek_r1_qwen_7b_q8.csv"
  metrics_path: "${deepseek.data_dir}/metrics_deepseek_r1_qwen_7b_q8.csv"

  download:
    repo_id: "${deepseek_r1_qwen_7b_q8.repo_id}"
    filename: "${deepseek_r1_qwen_7b_q8.filename}"
    model_dir: "${deepseek.model_dir}"
    token: null

  infer:
    class_name: "${deepseek.class_name}"
    script_path: "${path.script}"
    model_path: "${deepseek.model_dir}/${deepseek_r1_qwen_7b_q8.filename}"
    n_ctx: 2048
    n_threads: "${n_threads}"
    n_gpu_layers: "${n_gpu_layers}"
    verbose: "${verbose}"
    stop:
      - "< | User | >"
    temperature: 0.6
    top_p: 0.95

